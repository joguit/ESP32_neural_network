{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red_neuronal_guardamos el modelo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTty0pQiTbsYnU4rjxueFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joguit/ESP32_neural_network/blob/master/Red_neuronal_guardamos_el_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FzxUpIphlwhq",
        "colab": {}
      },
      "source": [
        "\n",
        "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
        "#https://unipython.com/guarde-sus-modelos-para-mas-tarde-con-serializacion/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVGpqta5jZOG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# 1.   Red Neuronal con modelo guardado.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_BUIQ5FcCfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "25b094cb-b6b6-4c93-9d10-df222bc6e1d8"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "import os\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "\n",
        "# cargamos las 4 combinaciones de las compuertas XOR\n",
        "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
        "    #test_data = np.array([[1,1],[1,0],[0,1],[0,0]], \"float32\")\n",
        "# y estos son los resultados que se obtienen, en el mismo orden\n",
        "target_data = np.array([[0],[1],[1],[0]], \"float32\")\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=2, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy'])\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(training_data, target_data, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(training_data, target_data, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "print (model.predict(training_data).round())\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# later...\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(training_data, target_data, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "binary_accuracy: 100.00%\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "Saved model to disk\n",
            "Loaded model from disk\n",
            "accuracy: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2FoGHXchxqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "64273c19-d5f7-4e7e-935b-c9da37031e69"
      },
      "source": [
        "test_data = np.array([[1,1],[1,0],[0,1],[0,0]], \"float32\")\n",
        "print (model.predict(test_data).round())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}